{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Open in Colab](http://colab.research.google.com/github/knowbodynos/fierai/blob/master/demo/04-Text_Generation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-10-14 03:42:16--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/text-generation/run_generation.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.200.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.200.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11046 (11K) [text/plain]\n",
      "Saving to: ‘data/run_generation.py’\n",
      "\n",
      "     0K ..........                                            100% 68.4M=0s\n",
      "\n",
      "2020-10-14 03:42:16 (68.4 MB/s) - ‘data/run_generation.py’ saved [11046/11046]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Install transformers package\n",
    "pip install transformers\n",
    "\n",
    "# Download GPT-2 fine-tuning script\n",
    "wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py\n",
    "wget data https://raw.githubusercontent.com/huggingface/transformers/master/examples/text-generation/run_generation.py\n",
    "\n",
    "    \n",
    "# Download/untar data\n",
    "curl https://file.io/Vr3tfD7AVqo6 --output corpus.tar.gz && \\\n",
    "    tar xzfv corpus.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_language_modeling.py \\\n",
    "    --output_dir=output \\\n",
    "    --overwrite_output_dir \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=gpt2 \\\n",
    "    --do_train \\\n",
    "    --train_data_file=data/corpus.train.txt \\\n",
    "    --do_eval \\\n",
    "    --eval_data_file=data/corpus.valid.txt \\\n",
    "    --per_gpu_train_batch_size=1 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --run_name=fieri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-13 02:45:02.653825: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2020-10-13 02:45:02.653870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czfv gpt2-finetuned.tar.gz runs/ output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp gpt2-tuned.tar.gz /content/drive/My\\ Drive/colab-runs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
