{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Open in Colab](http://colab.research.google.com/github/knowbodynos/fierai/blob/master/demo/04-Text_Generation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-10-14 03:42:16--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/text-generation/run_generation.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.200.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.200.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11046 (11K) [text/plain]\n",
      "Saving to: ‘data/run_generation.py’\n",
      "\n",
      "     0K ..........                                            100% 68.4M=0s\n",
      "\n",
      "2020-10-14 03:42:16 (68.4 MB/s) - ‘data/run_generation.py’ saved [11046/11046]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Install transformers package\n",
    "pip install transformers\n",
    "\n",
    "# Download GPT-2 fine-tuning script\n",
    "wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py\n",
    "    \n",
    "# Download/untar data\n",
    "curl https://file.io/Vr3tfD7AVqo6 --output corpus.tar.gz && \\\n",
    "    tar xzfv corpus.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GPT-2 causal language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div display=\"inline\">\n",
    "<img src=\"http://jalammar.github.io/images/xlnet/transformer-decoder-block-self-attention-2.png\" width=400>\n",
    "<img src=\"http://jalammar.github.io/images/gpt2/gpt2-self-attention-1-2.png\" width=500>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_language_modeling.py \\\n",
    "    --output_dir=output \\\n",
    "    --overwrite_output_dir \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=gpt2 \\\n",
    "    --do_train \\\n",
    "    --train_data_file=data/corpus.train.txt \\\n",
    "    --do_eval \\\n",
    "    --eval_data_file=data/corpus.valid.txt \\\n",
    "    --per_gpu_train_batch_size=1 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --run_name=fieri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://d2l.ai/_images/beam-search.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "base_model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n",
    "tuned_model = GPT2LMHeadModel.from_pretrained('output', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"i'm guy fieri and\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pre-trained on millions of scraped websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm guy fieri and I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy fieri. I'm a guy f\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "output = base_model.generate(input_ids, max_length=200, seed=42, temperature=1.1)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fine-tuned on 1000 hours of Diners, Drive-ins, and Dives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/UHy3TzR.png\" width=500>\n",
    "<div display=\"inline\">\n",
    "<img src=\"https://i.imgur.com/EczFvkt.jpeg\" width=400>\n",
    "<img src=\"https://i.imgur.com/w6APEQO.jpeg\" width=400>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm guy fieri and were rolling out looking for americas greatest diners drive ins and dives this trip get after that were racing through charlotte north carolina put your seatbelt on you might need it with nascar driver clint boyer along for the ride howd you drop the nascar right into my cooking show bird ill take another one owes a reborn triple d favorite going full throttle with their burgers youre talking this thing like a coyote got a crazy go kart pitstop is this the drive part of diners drive ins and dives dishing out first place fixings theres nothing i would change about the sandwich and were crossing the finish line what do you say at a funky food truck thats the question now for triple d. im here in charlotte north carolina love it this is funky. funky yes it is crazy good time carolina bada bing is my favorite place to eat awesome chicken nugget thanks for keeping it real with the characters of\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "output = tuned_model.generate(input_ids, max_length=200, temperature=1.1)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language processing is what makes true greek food unique and different she did not take her greek specialties and just like her recipes visitors can expect to see some familiar faces. familiar faces. new places and more off the hook flavors. this is\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"natural language processing is\", return_tensors='pt')\n",
    "output = tuned_model.generate(input_ids, max_length=50, seed=None, temperature=1.1, do_sample=True)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czfv gpt2-finetuned.tar.gz runs/ output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp gpt2-tuned.tar.gz /content/drive/My\\ Drive/colab-runs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
